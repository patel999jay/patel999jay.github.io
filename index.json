[{"authors":["admin"],"categories":null,"content":"Jay Patel is a PhD student of Electrical \u0026 Computer Engineering at the Dalhousie ISL Lab. His research interests include electronics \u0026 communications, distributed underwater robotics, mobile computing and programmable matter. He leads the Underwater Robotic group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\n","date":1607115798,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607115798,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://patel999jay.github.io/author/jay-patel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jay-patel/","section":"authors","summary":"Jay Patel is a PhD student of Electrical \u0026 Computer Engineering at the Dalhousie ISL Lab. His research interests include electronics \u0026 communications, distributed underwater robotics, mobile computing and programmable matter.","tags":null,"title":"Jay Patel","type":"authors"},{"authors":["Jay Patel","Mae Seto"],"categories":null,"content":"Abstract A cross-domain communications network for above and below water marine robots, based on code-division multiple access (CDMA), is reported. CDMA is a promising physical layer and multiple access technique for underwater acoustic sensor networks as it: i) is robust to frequency selective fading, ii) compensates for multi-path effects at the receiver, and iii) allows receivers to distinguish amongst signals simultaneously transmitted by multiple devices. Consequently, CDMA increases channel re-use and reduces packet retransmissions, which results in decreased energy consumption and increased network throughput. The proposed CDMA network for autonomous co-ordination and networking is applied to marine robots separated by extended ranges to transmit images / information from underwater to above-water. The work involves a complete communications protocol stack from the physical to the application layer. Simulations of the proposed network were performed with Network Simulator-3 (NS-3). The proposed protocol leverages CDMA properties to achieve multiple access to the scarce underwater bandwidth while previous reported work with underwater channels only consider CDMA for the physical layer encoding. Simulations shows the proposed underwater acoustic network protocol outperforms other existing ones. The next step is preliminary testing in-water. ","date":1607115798,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607115798,"objectID":"f55469babe9d0b5955c205d2ea1c2240","permalink":"https://patel999jay.github.io/talk/asacdma2020/","publishdate":"2020-12-04T17:03:18-04:00","relpermalink":"/talk/asacdma2020/","section":"talk","summary":"A cross-domain communications network for above and below water marine robots, based on CDMA is reported.","tags":["Underwater channel characterization","Underwater shallow water communication","Underwater Acoustic Communication"],"title":"CDMA-based multi-domain communications network for marine robots","type":"talk"},{"authors":["Jay Patel"],"categories":[],"content":"WOSS Integration Framework with Acoustic Toolbox with NS3-dev (with Database, NETCDF4 and HDF5 support) WOSS is a multi-threaded C++ framework that permits the integration of any existing underwater channel simulator that expects environmental data as input and provides as output a channel realization.\nCurrently, WOSS integrates the Bellhop ray-tracing program.\nThanks to its automation the user only has to specify the location in the world and the time where the simulation should take place. This is done by setting the simulated date and the wanted latitude and longitude of every node involved. The simulator automatically handles the rest (see technical description).\nWOSS can be integrated in any network simulator or simulation tool that supports C++.\nYou can find the WOSS repository here on github\n\u0026lsquo;woss-ns3\u0026rsquo; relies on the following libraries:\n- WOSS - NetCDF - Acoustic Toolbox  First make sure you have gfortran,gcc and gcxx compiler.\nPlease checked if the GNU Fortran compiler was in my system by typing gfortran --version:\nGNU Fortran (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0 Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  If you go for the GNU compiler, type:\nexport FC=gfortran  Install latest Acoustic Toolbox (March 2019) cd ${HOME}/Documents wget http://telecom.dei.unipd.it/ns/woss/files/at.zip tar -xzf at.zip cd at/at make sudo make install  Once installed, let\u0026rsquo;s tell the system where to find our new libraries: (Please replace ns with your hostname\nexport PATH=/home/ns/Documents/at/at/Bellhop:/home/ns/Documents/at/at/:$PATH  You have to build support for NETCDF4 and HDF5 for NS3, WOSS and Acoustic Toolbox, Please make sure you follow this steps for installation :\nexport environment export F77=gfortran export FC=gfortran export CC=gcc export CXX=g++ export CFLAGS=-fPIC  Step 1. Install compilers and building tools First let\u0026rsquo;s check which Linux are you running with the command:\nlsb_release -ds  Will return something like:\nDebian GNU/Linux 9.8 (stretch)   For Debian/Ubuntu/Linux Mint:  sudo apt-get update sudo apt-get install wget nano gfortran m4 build-essential  Step 2. Install NETCDF Until version 4.1.3, NETCDF was bundled in a single package. Since then, has been split off into independent distributions (netCDF-C, netCDF-Fortran, netCDF-Java, netCDF-Python, netCDF-C++ and so on).\nLet\u0026rsquo;s start with downloading and installing netCDF-C in a new folder called netcdf in user home directory (e.g. /home/ns/):\nwget http://telecom.dei.unipd.it/ns/woss/files/netcdf-c-4.7.3.tar.gz tar -xzf netcdf-c-4.7.3.tar.gz cd netcdf-c-4.7.3 ./configure --prefix=${HOME}/netcdf --disable-dap --disable-netcdf-4 --enable-shared make make check sudo make install cd ${HOME}  Step 3. Now please install HDF5 support for NETCDF wget http://telecom.dei.unipd.it/ns/woss/files/hdf5-1.8.13.tar.gz tar -xzf hdf5-1.8.13.tar.gz cd hdf5-1.8.13 ./configure --enable-shared --prefix=${HOME}/netcdf --disable-dap --enable-fortran #If above command didn't work then please try ./configure --enable-shared --prefix=${HOME}/netcdf make make check sudo make install cd ${HOME}  Step 4. Again configure NETCDF with HDF5 support cd netcdf-c-4.7.3 ./configure --prefix=${HOME}/netcdf --disable-dap --enable-netcdf-4 --enable-shared CPPFLAGS=\u0026quot;$CPPFLAGS -I${HOME}/netcdf/include\u0026quot; LDFLAGS=\u0026quot;$LDFLAGS -L${HOME}/netcdf/lib\u0026quot; --enable-fortran --enable-cxx make make check sudo make install cd ${HOME}  Step 5. Now install NETCDF4 C++ support wget http://telecom.dei.unipd.it/ns/woss/files/netcdf-cxx4-4.3.1.tar.gz tar -xzf netcdf-cxx4-4.3.1.tar.gz cd netcdf-cxx4-4.3.1 ./configure --prefix=${HOME}/netcdf --enable-shared CPPFLAGS=\u0026quot;$CPPFLAGS -I${HOME}/netcdf/include\u0026quot; LDFLAGS=\u0026quot;$LDFLAGS -L${HOME}/netcdf/lib\u0026quot; make make check sudo make install cd ${HOME}  Once installed, let\u0026rsquo;s tell the system where to find our new libraries and export variables to .bashrc:\nexport NETCDF=${HOME}/netcdf export PATH=$NETCDF/bin:$PATH export NETCDF_INCDIR=$NETCDF/include export NETCDF_LIBDIR=$NETCDF/lib export LD_LIBRARY_PATH=$NETCDF/lib:$LD_LIBRARY_PATH export PATH NETCDF  Step 6. Install WOSS library support wget http://telecom.dei.unipd.it/ns/woss/files/WOSS-v1.10.0.tar.gz tar -xzf WOSS-v1.10.0.tar.gz cd woss-1.10.0 ./autogen.sh ./configure --with-netcdf4=${HOME}/netcdf --with-pthread make make check sudo make install wget http://telecom.dei.unipd.it/ns/woss/files/WOSS-dbs-v1.4.0.tar.gz tar -xzf WOSS-dbs-v1.4.0.tar.gz cd dbs/bathymetry wget https://www.bodc.ac.uk/data/open_download/gebco/GEBCO_15SEC/zip/ #this is almost ~ 12 GB database. tar -xzf GEBCO_2019.zip #This is database used by WOSS, more details are available on http://telecom.dei.unipd.it/ns/woss/doxygen/database.html  NS3-dev Installation cd Documents/ mkdir workspace cd workspace wget https://www.nsnam.org/release/ns-allinone-3.30.tar.bz2 tar xjf ns-allinone-3.30.tar.bz2 cd ns-allinone-3.30/ ./build.py --enable-examples --enable-tests cd ns-3.30/ ./waf --run scratch/scratch-simulator #To check everything working fine  Please don\u0026rsquo;t use sudo to build ns3-dev as it makes conficts when woss try to call bellhop.exe in runtime, to chech you have correctly set your PATH for acoustic toolbox,\nwhich bellhop.exe  It will show you path of your bellhop.exe, same like this,\n/home/ns/Documents/at/bin/bellhop.exe  configure WOSS libraries for ns3-dev cd ${HOME}/Documents/workspace/ns-allinone-3.30/ns-3.30/src git clone https://github.com/MetalKnight/woss-ns3.git tar xjf woss-ns3-master.zip #Remove zip file from src folder as this will conflict while building NS-3 mv woss-ns3-master woss-ns3 #Rename folder as woss-ns3, make sure folder name is correct to avoid config errors cd .. ./waf -d debug --enable-tests --enable-examples --enable-sudo --with-woss-source=/home/ns/woss-1.10.0/ --with-woss-library=/home/ns/woss-1.10.0/woss --with-netcdf4-install=${HOME}/netcdf configure CXXFLAGS=\u0026quot;-Wall -Werror -Wno-unused-variable\u0026quot; #this configure your ns3, Please make sure woss source(in my case i.e /home/ns/woss-1.10.0/) is correct and installed woss library (in my case i.e /home/ns/woss-1.10.0/woss) is provided with correct path, also make sure you put the correct path for netCDF(in my case i.e${HOME}/netcdf)  You can see, ./waf will configure and please check if you got message in second last command line saying\n# WOSS Integration Framework : enabled  In my case, It looks like,\nmedit@medit-Vostro-230:~/Documents/workspace/ns-allinone-3.30/ns-3.30$ ./waf -d debug --enable-tests --enable-examples --enable-sudo --with-woss-source=/home/medit/woss-1.9.0/ --with-woss-library=/home/medit/woss-1.9.0/woss --with-netcdf4-install=${HOME}/netcdf configure Setting top to : /home/ns/Documents/workspace/ns-allinone-3.30/ns-3.30 Setting out to : /home/ns/Documents/workspace/ns-allinone-3.30/ns-3.30/build Checking for 'gcc' (C compiler) : /usr/bin/gcc Checking for cc version : 7.4.0 Checking for 'g++' (C++ compiler) : /usr/bin/g++ Checking for compilation flag -Wl,--soname=foo support : ok Checking for compilation flag -std=c++11 support : ok Checking boost includes : headers not found, please provide a --boost-includes argument (see help) Checking boost includes : headers not found, please provide a --boost-includes argument (see help) Checking for program 'python' : /usr/bin/python3 Checking for python version \u0026gt;= 2.3 : 3.6.9 python-config : not found Checking for library python3.6m in LIBDIR : not found Checking for library python3.6m in python_LIBPL : yes Checking for header Python.h : Distutils not installed? Broken python installation? Get python-config now! Checking for click location : not found Checking for program 'pkg-config' : /usr/bin/pkg-config Checking for 'gtk+-3.0' : not found Checking for 'libxml-2.0' : not found checking for uint128_t : not found checking for __uint128_t : yes Checking high precision implementation : 128-bit integer (default) Checking for header stdint.h : yes Checking for header inttypes.h : yes Checking for header sys/inttypes.h : not found Checking for header sys/types.h : yes Checking for header sys/stat.h : yes Checking for header dirent.h : yes Checking for header stdlib.h : yes Checking for header signal.h : yes Checking for header pthread.h : yes Checking for header stdint.h : yes Checking for header inttypes.h : yes Checking for header sys/inttypes.h : not found Checking for library rt : yes Checking for header sys/ioctl.h : yes Checking for header net/if.h : yes Checking for header net/ethernet.h : yes Checking for header linux/if_tun.h : yes Checking for header netpacket/packet.h : yes Checking for NSC location : not found Checking for 'sqlite3' : not found Checking for header linux/if_tun.h : yes Checking the given WOSS source code path : /home/ns/woss-1.9.0/ (given) Checking the given WOSS library path : /home/ns/woss-1.9.0/woss (given) Checking the given NetCDF4 and HDF5 install path : /home/ns/netcdf (given) WOSS source code path is valid : /home/ns/woss-1.9.0/woss WOSS source code path is valid : /home/ns/woss-1.9.0/woss/woss_def WOSS source code path is valid : /home/ns/woss-1.9.0/woss/woss_db Checking the given WOSS library : yes NetCDF4 and HDF5 source code path : /home/ns/netcdf/include Checking the given NETCDF4 and HDF5 libraries : yes Checking for program 'sudo' : /usr/bin/sudo Checking for program 'valgrind' : not found Checking for 'gsl' : not found libgcrypt-config : not found Checking for compilation flag -fstrict-aliasing support : ok Checking for compilation flag -fstrict-aliasing support : ok Checking for compilation flag -Wstrict-aliasing support : ok Checking for compilation flag -Wstrict-aliasing support : ok Checking for program 'doxygen' : not found ---- Summary of optional NS-3 features: Build profile : debug Build directory : BRITE Integration : not enabled (BRITE not enabled (see option --with-brite)) DES Metrics event collection : not enabled (defaults to disabled) Emulation FdNetDevice : enabled Examples : enabled File descriptor NetDevice : enabled GNU Scientific Library (GSL) : not enabled (GSL not found) Gcrypt library : not enabled (libgcrypt not found: you can use libgcrypt-config to find its location.) GtkConfigStore : not enabled (library 'gtk+-3.0 \u0026gt;= 3.0' not found) MPI Support : not enabled (option --enable-mpi not selected) NS-3 Click Integration : not enabled (nsclick not enabled (see option --with-nsclick)) NS-3 OpenFlow Integration : not enabled (Required boost libraries not found) Network Simulation Cradle : not enabled (NSC not found (see option --with-nsc)) PlanetLab FdNetDevice : not enabled (PlanetLab operating system not detected (see option --force-planetlab)) PyViz visualizer : not enabled (Python Bindings are needed but not enabled) Python Bindings : not enabled (Python library or headers missing) Real Time Simulator : enabled SQlite stats data output : not enabled (library 'sqlite3' not found) Tap Bridge : enabled Tap FdNetDevice : enabled Tests : enabled Threading Primitives : enabled Use sudo to set suid bit : enabled WOSS Integration Framework : enabled XmlIo : not enabled (library 'libxml-2.0 \u0026gt;= 2.7' not found) 'configure' finished successfully (2.808s)  Check out second last line to make sure everything is perfectly configure.\nThen build your ns3 again,\n./waf build CXXFLAGS=\u0026quot;-Wall -Werror -Wno-unused-variable\u0026quot;  you\u0026rsquo;ll see the following,\nWaf: Leaving directory `/home/ns/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Build commands will be stored in build/compile_commands.json 'build' finished successfully (11m35.055s) Modules built: antenna aodv applications bridge buildings config-store core csma csma-layout dsdv dsr energy fd-net-device flow-monitor internet internet-apps lr-wpan lte mesh mobility mpi netanim (no Python) network nix-vector-routing olsr point-to-point point-to-point-layout propagation sixlowpan spectrum stats tap-bridge test (no Python) topology-read traffic-control uan virtual-net-device wave wifi wimax woss-ns3 (no Python) Modules not built (see ns-3 tutorial for explanation): brite click openflow visualizer  Please run one of the example from scratch,\n./waf --run scratch/scratch-simulator  If you see the below output, Hola ! Its working now.\nWaf: Entering directory `/home/ns/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Waf: Leaving directory `/home/ns/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Build commands will be stored in build/compile_commands.json 'build' finished successfully (0.749s) Scratch Simulator  Then Run WOSS Aloha Example with following example (please note that scratch folder is not yet added to module so you have to manually run your examples from the woss-ns3/examples folder itself.)\nmedit@medit-Vostro-230:~/Documents/workspace/ns-allinone-3.30/ns-3.30$ ./waf --run src/woss-ns3/examples/woss-aloha-example Waf: Entering directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Waf: Leaving directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Build commands will be stored in build/compile_commands.json 'build' finished successfully (1.731s) WossManagerResDbMT::checkConcurrentThreads() 6 WossManagerResDbMT::checkConcurrentThreads() 4 Received a packet of size 1000 bytes Received a total of 1000 bytes at sink  Troubleshoot  If you\u0026rsquo;re running example and run into problem with tap-creator like following then you have to manually change few settings.  ./waf --run src/woss-ns3/examples/woss-aloha-example --command-template=\u0026quot;gdb --args %s \u0026lt;args\u0026gt;\u0026quot;  Waf: Entering directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' * Several tasks use the same identifier. Please check the information on https://waf.io/apidocs/Task.html?highlight=uid#waflib.Task.Task.uid - object 'SuidBuild_task' ( {task 140252058325512: SuidBuild_task -\u0026gt; }) defined in 'tap-creator' - object 'SuidBuild_task' ( {task 140252058325624: SuidBuild_task -\u0026gt; }) defined in 'tap-creator' - object 'SuidBuild_task' ( {task 140252058325736: SuidBuild_task -\u0026gt; }) defined in 'tap-creator' Waf: Leaving directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Build commands will be stored in build/compile_commands.json 'build' finished successfully (2.892s)  first figure out the problem with gdb command by running following command,\n./waf --run src/woss-ns3/examples/woss-aloha-example --command-template=\u0026quot;gdb --args %s \u0026lt;args  Then maybe the easier one for the time being, open the /home/usr/netcdf/include/ncGroup.h and remove the line 18 from that file, which is not used by the library anyway.\nIf you\u0026rsquo;re not able to find or use the common shared files/library,  medit@medit-Vostro-230:~/Documents/workspace/ns-allinone-3.30/ns-3.30$ ./waf --run src/woss-ns3/examples/woss-aloha-example Waf: Entering directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Waf: Leaving directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Build commands will be stored in build/compile_commands.json 'build' finished successfully (1.713s) /home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build/src/woss-ns3/examples/ns3.30-woss-aloha-example-debug: error while loading shared libraries: libWOSS.so.0: cannot open shared object file: No such file or directory Command ['/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build/src/woss-ns3/examples/ns3.30-woss-aloha-example-debug'] exited with code 127  please do following to solve the error,\nEdit /etc/ld.so.conf or create something in /etc/ld.so.conf.d/ to add /usr/local/lib and /usr/local/lib64. Then run ldconfig.\nIn my case,\nsudo nano /etc/ld.so.conf  Please make sure you have the correct lib in the same file, in my case it was,\ninclude /etc/ld.so.conf.d/*.conf add /usr/local/lib:/usr/local/lib64 //added by Jay to access common or shared libraries  save the same file and configure again by\nsudo ldconfig  It should work now. In my case, it worked\nmedit@medit-Vostro-230:~/Documents/workspace/ns-allinone-3.30/ns-3.30$ ./waf --run src/woss-ns3/examples/woss-aloha-example Waf: Entering directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Waf: Leaving directory `/home/medit/Documents/workspace/ns-allinone-3.30/ns-3.30/build' Build commands will be stored in build/compile_commands.json 'build' finished successfully (1.731s) WossManagerResDbMT::checkConcurrentThreads() 6 WossManagerResDbMT::checkConcurrentThreads() 4 Received a packet of size 1000 bytes Received a total of 1000 bytes at sink  If you get the error of ./autogen.sh: 3: ./autogen.sh: aclocal: not found or ./autogen.sh: 3: ./autogen.sh: libtoolize: not found then please install automake essentials for build in the ubuntu. You can also install with following commands:  sudo apt-get install autotools-dev sudo apt-get install automake sudo apt-get install libtool m4 automake  You can also download all this instruction to your local machine.   Download  References  http://telecom.dei.unipd.it/ns/woss/, Special Thanks to  Federico Guerra https://www.nsnam.org/ https://github.com/MetalKnight/woss-ns3 https://github.com/javirg/SWAN-Support/blob/master/recipes/build_linux_netcdf.md  ","date":1603147579,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603147579,"objectID":"b8a510964480cb72f8185a0df82aae7f","permalink":"https://patel999jay.github.io/post/woss-integration-ns3/","publishdate":"2020-10-19T19:46:19-03:00","relpermalink":"/post/woss-integration-ns3/","section":"post","summary":"WOSS Integration Framework with Acoustic Toolbox with NS3-dev","tags":["Underwater Acoustic Communication","Bellhop Channel Modelling","Heterogeneous marine robots","Network Simulator 3"],"title":"WOSS Integration with NS-3","type":"post"},{"authors":["Jay Patel","Mae Seto"],"categories":[],"content":"Abstract The underwater acoustic (UWA) channel is challenging as a propagation medium for wireless transmissions due to its spatial-temporal variability from high ambient noise, limited bandwidth, frequency-dependent losses, variable latency and time-space-frequency variable multi-path effects. Prior to deploying marine robots, the UWA channel should be characterized for its local sound velocity profile, at both source and receiver(s) depths, bottom cover (e.g. sand, silt, mud, etc.) and bathymetry. At the transmission end, it matters the signalâ€™s carrier frequency, bandwidth, and pulse characteristics. With knowledge of both, it is possible to assess the operational communications range. This is especially so to develop and evaluate new medium access control (MAC) and routing level protocols. As a part of a project, three heterogeneous marine robots (unmanned underwater vehicle (UUV), unmanned surface vehicle (USV), and unmanned aerial vehicle (UAV)) collaboratively acquired situational awareness on a non-responsive floating target. This paper reports on the communications aspect. It presents models that assess the impact of the relative placement between a transmitter (USV) and receiver (UUV) through ray tracing and several sea-bed environmental/UWA channel conditions on operational communication range between UUV \\\u0026 USV.\n","date":1599669112,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599669112,"objectID":"0a76a6f8aa171682c1417783e1bfcc21","permalink":"https://patel999jay.github.io/publication/icua-2020/","publishdate":"2020-08-14T13:31:52-03:00","relpermalink":"/publication/icua-2020/","section":"publication","summary":"An Underwater channel characterization simulation","tags":["Underwater Acoustic Communication","Bellhop Channel Modelling","Heterogeneous marine robots"],"title":"Underwater channel characterization for shallow water multi-domain communications","type":"publication"},{"authors":["Jay Patel","Mae Seto"],"categories":null,"content":" Go to Publication for more details.   ","date":1599647400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599647400,"objectID":"e08c71b194d2d445665ee385c26a468b","permalink":"https://patel999jay.github.io/talk/icua2020/","publishdate":"2018-08-17T00:00:00Z","relpermalink":"/talk/icua2020/","section":"talk","summary":"An underwater channel characterization for shallow water conditions in the Atlantic offshore Halifax, Canada.","tags":["Underwater channel characterization","Underwater shallow water communication"],"title":"Underwater channel characterization for shallow water multi-domain communications","type":"talk"},{"authors":["Jay Patel"],"categories":[],"content":"FFT Magic - Time Domain to Frequency Domain Signal Visualization Anyone with a background in Physics or Engineering knows to some degree about signal analysis techniques, what these technique are and how they can be used to analyze, model and classify signals.\nLet\u0026rsquo;s start with Fun stuff ! Everyone heard of FFT word in their lifetime. Let\u0026rsquo;s dive deep into Frequency Domain for more details.\nLet\u0026rsquo;s plot some sound files in time domain. # required library imports import librosa import librosa.display import scipy as sp import IPython.display as ipd import matplotlib.pyplot as plt import numpy as np  # load audio file in the player audio_path = \u0026quot;audio/Data_00023.wav\u0026quot; ipd.Audio(audio_path)  # load audio file signal, sr = librosa.load(audio_path)  Below is the time domain representation of the signal. # plot waveform plt.figure(1) plt.figure(figsize=(18,5)) plt.plot(signal,'b') plt.xlabel('sample rate * time') plt.ylabel('energy') plt.grid()  Isn\u0026rsquo;t that interesting ?\nLet\u0026rsquo;s take this time domain signal into frequency domain and do some more interesting stuff !\nimport scipy as sp from scipy import fftpack import matplotlib as mpl tf = 60 # Final time dt = 0.1 # Time step t = np.arange(0,tf,dt) # Signal sample times  Calculate FFT sample_freq = sp.fftpack.fftfreq(len(signal),d=dt) # Frequency values (+,-) sig_fft = sp.fftpack.fft(signal) # Calculate FFT  plt.rc('figure', figsize = (18, 5)) # Reduces overall size of figures plt.rc('axes', labelsize=24, titlesize=24) plt.rc('figure', autolayout = True) # Adjusts supblot parameters for new size  plt.figure(2) plt.title(\u0026quot;FFT\u0026quot;,fontsize=24) plt.plot(sig_fft.real, label='real') plt.plot(sig_fft.imag,label='imag') plt.legend(loc=1)  Calculate and plot power spectrum for $f\u0026gt;0$.\npfs = np.where(sample_freq\u0026gt;0) # Select postive frequencies freqs = sample_freq[pfs] power = abs(sig_fft)[pfs]**2  plt.figure(3) plt.title(\u0026quot;FFT (power)\u0026quot;,fontsize=24) plt.xlabel(\u0026quot;$f$\u0026quot;) plt.plot(freqs,power,'b') plt.grid()  /home/jay/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py:2366: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect. warnings.warn(\u0026quot;This figure includes Axes that are not compatible \u0026quot;  Filter and inverse transform Crude low-pass filter: cut out all frequencies greater than 25 KHz.\nsig_fft[abs(sample_freq)\u0026gt; 25] = 0  Calculate inverse FFT: sig_filtered = sp.fftpack.ifft(sig_fft)  plt.figure(4) plt.title(\u0026quot;filtered signal\u0026quot;,fontsize=14) plt.xlabel(\u0026quot;$t$\u0026quot;) plt.plot(np.real(sig_filtered),'b') plt.grid()  Voila ! This is our original time domain signal !\nLet\u0026rsquo;s Have More deep understanding of Time domain signal, Frequency Domain signal and Time-Frequency Representation! Let Plot all three things together and Have python fun !\nfrom mpl_toolkits.mplot3d import Axes3D import numpy as np from scipy.fftpack import fft import matplotlib.pyplot as plt from matplotlib import animation from matplotlib import cm t_n = 10 N = 1000 T = t_n / N f_s = 1 / T def get_fft_values(y_values, T, N, f_s): f_values = np.linspace(0.0, 1.0 / (2.0 * T), N // 2) fft_values_ = fft(y_values) fft_values = 2.0 / N * np.abs(fft_values_[0:N // 2]) return f_values, fft_values x_value = np.linspace(0, t_n, N) amplitudes = [4, 6, 8, 10, 14] frequencies = [6.5, 5, 3, 1.5, 1] y_values = [amplitudes[ii] * np.sin(2 * np.pi * frequencies[ii] * x_value) for ii in range(0, len(amplitudes))] composite_y_value = np.sum(y_values, axis=0) f_values, fft_values = get_fft_values(composite_y_value, T, N, f_s) colors = ['k', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b'] fig = plt.figure(figsize=(8, 8)) ax = fig.add_subplot(111, projection='3d') ax.set_xlabel(\u0026quot;\\nTime [s]\u0026quot;, fontsize=16) ax.set_ylabel(\u0026quot;\\nFrequency [Hz]\u0026quot;, fontsize=16) ax.set_zlabel(\u0026quot;\\nAmplitude\u0026quot;, fontsize=16) y_values_ = [composite_y_value] + list(reversed(y_values)) frequencies = [1, 1.5, 3, 5, 6.5] def init(): # Plot the surface. for ii in range(0, len(frequencies)): signal = y_values_[ii] color = colors[ii] length = signal.shape[0] x = np.linspace(0, 10, 1000) y = np.array([frequencies[ii]] * length) z = signal if ii == 0: linewidth = 4 else: linewidth = 2 ax.plot(list(x), list(y), zs=list(z), linewidth=linewidth, color=color) x = [10] * 75 y = f_values[:75] z = fft_values[:75] * 3 ax.plot(list(x), list(y), zs=list(z), linewidth=2, color='red') plt.tight_layout() return fig, def animate(i): # azimuth angle : 0 deg to 360 deg ax.view_init(elev=10, azim=i*4) return fig, # Animate ani = animation.FuncAnimation(fig, animate, init_func=init, frames=90, interval=50, blit=True) plt.show()  fn = 'rotate_azimuth_angle_3d_surf' ani.save(fn+'.gif',writer='imagemagick',fps=1000/50)  Let\u0026rsquo;s get ready to blow your Mind ! References :  http://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/ FFT, Valerio Velardo - The Sound of AI, https://github.com/musikalkemist/AudioSignalProcessingForML  ","date":1599240636,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599240636,"objectID":"ecf4e3614030dbdf39254f111d95d520","permalink":"https://patel999jay.github.io/post/fft-fun/","publishdate":"2020-09-04T14:30:36-03:00","relpermalink":"/post/fft-fun/","section":"post","summary":"FFT Magic - Time Domain to Frequency Domain Signal Visualization","tags":["python"],"title":"FFT Fun","type":"post"},{"authors":["Jay Patel"],"categories":[],"content":"Bellhop - Ocean simulation modeling What is BELLHOP ?\n BELLHOP is a beam tracing model for predicting acoustic pressure fields in ocean environments. BELLHOP can produce a variety of useful outputs including transmission loss, eigenrays, arrivals, and received time-series. It also allows for range-dependence in the top and bottom boundaries (altimetry and bathymetry), as well as in the sound speed profile (SSP). BELLHOP is implemented in Fortran, Matlab, and Python and used on multiple platforms (Mac, Windows, and Linux).   Figure 1: BELLHOP structure  WHY BELLHOP?  Underwater communication channel is a relatively difficult transmission medium due to the variability of link quality depending on location and applications. Before deploying any kind of vehicles underwater, one should predict the underwater communication system performance which is based on the sound frequency transmitted underwater.  Why do you need to analyze the uw-comms performance?\n  To analyze impact of channel characteristics on underwater communications,\n  prior to deploying robots, predict communication system performance,\n  provide guidance on best physical layout to deploy underwater vehicles,\n  provide estimates on parameters for link budget calculation,\n  Because it will provide you a rough idea about how far you can communicate within network which is also known as an operation range for communication.\n  BELLHOP reads these files depending on options selected within the main environmental file.\n  There are various options for which you can run bellhop are:\n ray tracing option, eigenray option, transmission loss option, an arrivals calculation option.    Installation  Please download newer version from Bellhop, Bellhop Mirror#1 or Bellhop Mirror#2. Unzip the downloaded file to local machine and go to that folder. If you\u0026rsquo;re using the Unix base system then open command prompt and go to the same folder where you extracted your zip.  cd at/at make all sudo make install   If you\u0026rsquo;re using bellhop on Windows 10 machine then you also need to download the Win10 Binary executable files from here. Please also extract that to the folder at.  Detailed Installation Instructions based on OS   Windows 10  Ubuntu 20.04  Mac OS  More Details  Sound Speed Profile of Bedford Basin (taken on 13-10-17)  Figure 2: Sound Speed Profile  How to Plot SSP\u0026rsquo;s using ARLPY ? # SSP Plotting using ARLPY import arlpy.uwapm as pm import arlpy.plot as plt import numpy as np env = pm.create_env2d() ssp = [ [ 0, 1540], # 1540 m/s at the surface [10, 1530], # 1530 m/s at 10 m depth [20, 1532], # 1532 m/s at 20 m depth [25, 1533], # 1533 m/s at 25 m depth [30, 1535] # 1535 m/s at the seabed ] env = pm.create_env2d(soundspeed=ssp) pm.plot_ssp(env, width=500)   Plotting an Environment # Plotting an Environment using ARLPY pm.plot_env(env, width=900)   Eigenrays  Eigenray plots show just the rays that connect the source to a receiver.  # Eigenrays using ARLPY import arlpy.uwapm as pm import arlpy.plot as plt import numpy as np env = pm.create_env2d() rays = pm.compute_eigenrays(env) pm.plot_rays(rays, env=env, width=900)   Figure 3: Eigenrays using ARLPY   compute the arrival structure at the receiver arrivals = pm.compute_arrivals(env) pm.plot_arrivals(arrivals, width=900)   arrivals[arrivals.arrival_number \u0026lt; 10][['time_of_arrival', 'angle_of_arrival', 'surface_bounces', 'bottom_bounces']]   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  time_of_arrival angle_of_arrival surface_bounces bottom_bounces     1 0.721796 22.538254 9 8   2 0.716791 -21.553932 8 8   3 0.709687 20.052078 8 7   4 0.705226 -19.034414 7 7   5 0.698960 17.484421 7 6   6 0.695070 -16.436060 6 6   7 0.689678 14.842224 6 5   8 0.686383 -13.766296 5 5   9 0.681901 12.133879 5 4   10 0.679223 -11.034208 4 4     # convert to a impulse response time series ir = pm.arrivals_to_impulse_response(arrivals, fs=96000) plt.plot(np.abs(ir), fs=96000, width=900)   Bathymetry Let's first start off by defining our bathymetry, a steep up-slope for the first 300 m, and then a gentle downslope:  # add/change bathy to env bathy = [ [0, 30], # 30 m water depth at the transmitter [300, 20], # 20 m water depth 300 m away [1000, 25] # 25 m water depth at 1 km ] # add/change SSP to env ssp = [ [ 0, 1540], # 1540 m/s at the surface [10, 1530], # 1530 m/s at 10 m depth [20, 1532], # 1532 m/s at 20 m depth [25, 1533], # 1533 m/s at 25 m depth [30, 1535] # 1535 m/s at the seabed ] # Appending ssp and bathy to existing env file env = pm.create_env2d( depth=bathy, soundspeed=ssp, bottom_soundspeed=1450, bottom_density=1200, bottom_absorption=1.0, tx_depth=15 ) pm.print_env(env)   name : arlpy bottom_absorption : 1.0 bottom_density : 1200 bottom_roughness : 0 bottom_soundspeed : 1450 depth : [[ 0. 30.] [ 300. 20.] [1000. 25.]] depth_interp : linear frequency : 25000 max_angle : 80 min_angle : -80 nbeams : 0 rx_depth : 10 rx_range : 1000 soundspeed : [[ 0. 1540.] [ 10. 1530.] [ 20. 1532.] [ 25. 1533.] [ 30. 1535.]] soundspeed_interp : spline surface : None surface_interp : linear tx_depth : 15 tx_directionality : None type : 2D  pm.plot_env(env, width=900)   Looks more interesting! Let's see what the eigenrays look like, and also the arrival structure:  rays = pm.compute_eigenrays(env) pm.plot_rays(rays, env=env, width=900)   We could also ignore the receiver, and plot rays launched at various angles:  rays = pm.compute_rays(env) pm.plot_rays(rays, env=env, width=900)   import numpy as np from scipy.interpolate import griddata import scipy.ndimage as ndimage from scipy.ndimage import gaussian_filter import scipy # from scipy.misc import imsave from matplotlib import cm import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from stl import mesh, Mode import matplotlib.tri as mtri from mpl_toolkits.mplot3d.axes3d import get_test_data from pandas import read_csv data = read_csv('bathy.txt', sep='\\s+', header=None, names=['x', 'y', 'depth']) x = np.arange(data.x.min(), data.x.max()+1) y = np.arange(data.y.min(), data.y.max()+1) X, Y = np.meshgrid(x, y) Z = griddata(data[['x','y']].values, -data['depth'].values, (X, Y), method='linear') # make the grid square Z[np.isnan(Z)] = 0 fig = plt.figure(figsize=(14, 8)) ax = fig.add_subplot(111) plt.imshow(Z) plt.show()   Figure 4: Bedford Basin Bathy 2D    Figure 5: Bedford Basin Bathy 3D   or place lots of receivers in a grid to visualize the acoustic pressure field (or equivalently transmission loss). We can modify the environment (env) without having to recreate it, as it is simply a Python dictionary object:\nenv['rx_range'] = np.linspace(0, 1000, 1001) env['rx_depth'] = np.linspace(0, 30, 301)  Transmission Loss - RUN TYPE BELLHOP OPTION(1:1): 'R' generates a ray file 'E' generates an eigenray file 'A' generates an amplitude-delay file (ascii) 'a' generate an amplitude-delay file (binary) 'C' Coherent TL calculation 'I' Incoherent TL calculation 'S' Semicoherent TL calculation (Lloyd mirror source pattern) - The number of beams, NBeams, should normally be set to 0, allowing BELLHOP to automatically select the appropriate value. The number needed increases with frequency and the maximum range to a receiver.   The pressure field, p, is then calculated for the specified grid of receivers, with a scaling such that $20\\ log10(|p|)$ is the transmission loss in dB.  tloss = pm.compute_transmission_loss(env) pm.plot_transmission_loss(tloss, env=env, clim=[-60,-30], width=900)   We see a complicated interference pattern, but an interesting focusing at 800 m at a 15 m depth. The detailed interference pattern is of course sensitive to small changes in the environment. A less sensitive, but more averaged out, transmission loss estimate can be obtained using the incoherent mode:\ntloss = pm.compute_transmission_loss(env, mode='incoherent') pm.plot_transmission_loss(tloss, env=env, clim=[-60,-30], width=900)   Source directionality Now, let's use a directional transmitter instead of an omni-directional one:  beampattern = np.array([ [-180, 10], [-170, -10], [-160, 0], [-150, -20], [-140, -10], [-130, -30], [-120, -20], [-110, -40], [-100, -30], [-90 , -50], [-80 , -30], [-70 , -40], [-60 , -20], [-50 , -30], [-40 , -10], [-30 , -20], [-20 , 0], [-10 , -10], [ 0 , 10], [ 10 , -10], [ 20 , 0], [ 30 , -20], [ 40 , -10], [ 50 , -30], [ 60 , -20], [ 70 , -40], [ 80 , -30], [ 90 , -50], [100 , -30], [110 , -40], [120 , -20], [130 , -30], [140 , -10], [150 , -20], [160 , 0], [170 , -10], [180 , 10] ]) env['tx_directionality'] = beampattern  tloss = pm.compute_transmission_loss(env) pm.plot_transmission_loss(tloss, env=env, clim=[-60,-30], width=900)   Now you can see the directionality and the sidelobe structure of the transmitter.  tloss = pm.compute_transmission_loss(env, mode='incoherent') pm.plot_transmission_loss(tloss, env=env, clim=[-60,-30], width=900)   Undulating water surface Finally, let's try adding a long wavelength swell on the water surface:  surface = np.array([[r, 0.5+0.5*np.sin(2*np.pi*0.005*r)] for r in np.linspace(0,1000,1001)]) env['surface'] = surface  tloss = pm.compute_transmission_loss(env) pm.plot_transmission_loss(tloss, env=env, clim=[-60,-30], width=900)   tloss = pm.compute_transmission_loss(env, mode='incoherent') pm.plot_transmission_loss(tloss, env=env, clim=[-60,-30], width=900)   Now, if I placed a receiver at 800 m, and 15 m depth, roughly where we see some focusing, what would the eigenrays and arrival structure look like?  env['rx_range'] = 800 env['rx_depth'] = 15  rays = pm.compute_eigenrays(env) pm.plot_rays(rays, env=env, width=900)   arrivals = pm.compute_arrivals(env) pm.plot_arrivals(arrivals, dB=True, width=900)   Note: We plotted the amplitudes in dB, as the later arrivals are much weaker than the first one, and better visualized in a logarithmic scale.\nBellhop3D   BELLHOP3D is a beam tracing model for predicting acoustic pressure fields in ocean environments.\n  It is an extension to 3D environments of the popular BELLHOP model and includes (optionally) horizontal refraction in the lat-long plane.\n  3D pressure fields can be calculated by a 2D model simply by running it on a series of radials (bearing lines) from the source.(This is the so-called Nx2D or 2.5D approach.)\n  BELLHOP3D includes 4 different types of beams:\n Cerveny Beams, Geometric Hat-Beams, Geometric Gaussian-Beams, Geometric Hat-Beams in Cartesian Coordinates    You can also download the sample notebook from here.\n  All code and setup files are also available on GitHub.\n  References  http://oalib.hlsresearch.com/AcousticsToolbox/ https://arlpy.readthedocs.io/en/latest/_static/bellhop.html  ","date":1599169887,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599169887,"objectID":"117c892d3df091279745ebb1c8ea1e08","permalink":"https://patel999jay.github.io/post/bellhop-acoustic-toolbox/","publishdate":"2020-09-03T18:51:27-03:00","relpermalink":"/post/bellhop-acoustic-toolbox/","section":"post","summary":"Bellhop Ray tracing model","tags":["Underwater Acoustic Communication","Bellhop Channel Modelling","Heterogeneous marine robots"],"title":"Bellhop Acoustic Toolbox","type":"post"},{"authors":["Jay Patel","Mae Seto"],"categories":[],"content":"Abstract Orthogonal Frequency Division Multiplexing (OFDM) is a multi-carrier digital communication technique which solves most of the digital communication problems such as inter-symbol interference (ISI), lower data rate, inter-carrier interference (ICI). It adds up an excessive amount of low data rate carriers to assemble high data rate communication system. Each low data rate carrier provides enough long symbol periods, which results in eliminating ISI. Orthogonality enables excellent feature providing each carrier a way to be closed spaced, although overlapped without ICI. The main contribution of this research is to demonstrate the OFDM concept in real time RF Communication while investigating its critical performance analysis. This framework integrates more than one embedded platforms such as RPi, Analog PlutoSDR and MATLAB. This may be an efficient way to transmit live images/video feed from one place to another for surveillance purposes. This research is more focused on transmitting live image taken with constant rate from Rpi video-camera to Analog Pluto, which transmit image over Radio channel and receive the same with different PlutoSDR at remote location.","date":1599057215,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599057215,"objectID":"f71d4ea74b6ae390df996c08619dd9ff","permalink":"https://patel999jay.github.io/publication/live-rf-image-transmission-using-ofdm-with-rpi-and-plutosdr/","publishdate":"2020-08-16T11:33:35-03:00","relpermalink":"/publication/live-rf-image-transmission-using-ofdm-with-rpi-and-plutosdr/","section":"publication","summary":"Live RF Image Transmission Using OFDM With RPi and PlutoSDR","tags":["PlutoSDR","OFDM","MATLAB"],"title":"Live RF Image Transmission Using OFDM With RPi and PlutoSDR","type":"publication"},{"authors":["Jay Patel","Niraj Tevar","Dr J M Rathod"],"categories":[],"content":"","date":1584746210,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584746210,"objectID":"5a49fade5b907cbd8338b572c1a2354d","permalink":"https://patel999jay.github.io/publication/low-cost-design-of-uhf-antenna-for-roof-mounted-vehicular-and-heavy-duty-applications/","publishdate":"2020-08-17T20:16:50-03:00","relpermalink":"/publication/low-cost-design-of-uhf-antenna-for-roof-mounted-vehicular-and-heavy-duty-applications/","section":"publication","summary":"","tags":["UHF antenna"],"title":"Low Cost Design of UHF Antenna for Roof Mounted Vehicular and Heavy Duty Applications","type":"publication"},{"authors":["Jay Patel","Mae Seto"],"categories":null,"content":"Abstract This paper reports on a cross-domain communication system for marine robots based on code-division multiple access (CDMA). The underwater communications channel is a difficult transmission medium due to its link quality variability which depends on location and the application. It also depends on environmental parameters which can vary temporally from hours to days to months to season. Understanding the channel characteristics for data transmission is essential to the development and evaluation of existing or new MAC and Routing Level protocols which better utilize the limited resources within this unpredictable channel. CDMA is the most promising physical layer and multiple access technique for underwater acoustic sensor networks because it: i) is robust to frequency selective fading, ii) compensates for multi-path effects at the receiver, and iii) allows receivers to distinguish among signals simultaneously transmitted by multiple devices. For these reasons, CDMA increases channel re-use and reduces packet retransmissions, which results in decreased energy consumption and increased network throughput. Development of a framework for autonomous co-ordination and networking of marine robot teams from extended ranges to transmit images/information from underwater to above water is proposed using CDMA which is a complete stack of communications protocol from the physical to the application layer for marine robots that spans multiple domains, i.e. under, on and above water. Simulation of the proposed network was performed using network simulator-3 (NS-3). The proposed protocol edge CDMA properties provide multiple access to the limited underwater bandwidth whereas previous reported work only considered CDMA for the physical layer. Simulations show the proposed protocol outperforms existing underwater acoustic network protocols.\n","date":1569196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569196800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://patel999jay.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"A cross-domain communication system for marine robots based on code-division multiple access (CDMA).","tags":["Cross-layer protocols","Network reliability","Security protocols","Robotics"],"title":"CDMA-Based Multi-Domain Communications Network for Marine Robots","type":"publication"},{"authors":["J. Ross","J. Lindsay","E. Gregson","A. Moore","Jay Patel","Mae Seto"],"categories":[],"content":"Abstract (Best Paper) This paper reports on a method to obtain a multi-domain (environment) awareness on a floating target (non-responsive ship, iceberg, other floating structure) using a heterogenous collaborative team of above, surface and underwater robots. This allows, for example, a ship approaching a non-responsive floating target to get information on the target from a safe stand-off prior to getting closer to further investigate or to attempt a boarding. This information enhances the safety of the boarding party. The ship can be a horizon (6 km) away from the floating target. The above-water unmanned aerial vehicles (UAV), integrated with optical cameras, obtains measurements of the above-water geometry using visual imagery to create an above-water three-dimensional model using photogrammetry methods. The below-water unmanned underwater vehicle is integrated with an imaging and profiling bathymetric sonars to capture the submerged hull geometry and features. An unmanned surface vehicle (USV) hosts an intelligent node which centrally controls the robotic collaboration by autonomously planning and distributing the mission for both the UUV and UAV. The results from the two are fused to yield a more complete picture of the floating target. We present results from simulations and a controlled in-water trial with an UUV, USV and UAV. The contributions from this work includes the robotic collaboration and autonomy across multiple domains, autonomous mission-planning and the fusing of multi-domain data. The scheduling of inter-dependent multi-robot task allocation is addressed in the autonomous mission-planning. The approach is validated in simulations and tested in-water. The in-water trials highlight the challenges and value of integrating sensors on distributed multi-domain robots towards a more complete picture on a floating target.\n","date":1560696307,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560696307,"objectID":"1611f16f7c2c114ab8df72e6ff961d65","permalink":"https://patel999jay.github.io/publication/collaboration-of-multi-domain-marine-robots-towards-above-and-below-water-characterization-of-floating-targets/","publishdate":"2020-08-16T11:45:07-03:00","relpermalink":"/publication/collaboration-of-multi-domain-marine-robots-towards-above-and-below-water-characterization-of-floating-targets/","section":"publication","summary":"Best Paper - A Multi-domain Robot collaberation","tags":["marine robotics","autonomy","autonomous mission-planning","acoustic propagation"],"title":"Collaboration of Multi Domain Marine Robots Towards Above and Below Water Characterization of Floating Targets","type":"publication"},{"authors":["Jay Patel"],"categories":[],"content":"# Author : Jay Patel # CDMA using Python import random import numpy as np %matplotlib inline from numpy import sin, pi from matplotlib import rcParams import matplotlib.pylab as plt rcParams.update({'font.size': 12})  f = 25000 t=np.linspace(0,8/f,400) carrier = lambda t: sin(2*pi*f*t) plt.figure(figsize=(16,6)) plt.plot(t,carrier(t),'b', lw=3) plt.title('25 KHz Carrier Wave',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.xlabel('Time[s]',size='16') plt.grid()  random.seed(\u0026quot;GPS PRN\u0026quot;) prn_seq = [random.choice([1,-1]) for i in range(16)] print(\u0026quot;Our PRN chip:\u0026quot;, str(prn_seq).replace('-1','0'))  Our PRN chip: [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]  f_prn = 25e3 / 10 prn_seq[int(100*f_prn)%16]  -1  f_prn = 25e3 / .10 prn_seq[int(100*f_prn)%16] def prn_np(t): return [ prn_seq[int(ti*f_prn)%16] for ti in t] plt.figure(figsize=(16,6)) plt.plot(t,prn_np(t), color='red',lw=4) plt.title('CDMA Psuedo Random Noise',size='20') plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.xlabel('Time(s)',size='16') plt.grid()  np.size([ prn_seq[int(ti*f_prn)%16] for ti in t])  400  Binary Phase Shift Keying (BPSK) The transmited GPS signal uses binary phase shift keying, signal changed by shift $\\pi=180^\\circ$ while it turns from 1 to -1, which can be done by multiplying the carefully constructed PRN above with the carrier!\nThis works because a $\\sin(x)\\times(-1) = \\sin(x-180^\\circ)$, in other words it\u0026rsquo;s exactly a 180 degree phase shift. We should see this as blips in sine wave every time our data changes from 1 to 0 or visa-versa :\nf = 25e3 f_prn = 25e3 /10 carrier = lambda t: sin(2*pi*f*t) def prn_np(t): return [ prn_seq[int(ti*f_prn)%16] for ti in t] #t=np.linspace(0,8/f_prn,400) t=np.linspace(0,16/f_prn,1400) signal = lambda t: carrier(t) * prn_np(t) plt.figure(figsize=(16,6)) plt.plot(t,prn_np(t),color='red',lw=4) plt.plot(t,signal(t),'b',lw=4,alpha=0.6) plt.title('CDMA BPSK',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.xlabel('Time[s]',size=12) plt.grid()  #t=np.linspace(0,8/f_prn,400) t=np.linspace(0,16/f_prn,1400) signal = lambda t: carrier(t) * prn_np(t) plt.figure(figsize=(16,6)) #plt.plot(t,prn_np(t),color='red',lw=4) plt.plot(t,signal(t),'b',lw=4,alpha=0.6) plt.title('CDMA BPSK',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.xlabel('Time[s]',size=12) plt.grid()  Too hard to be decipherable! The problem is that the carrier is running three orders of magnintude faster than the PRN!!! Unless we zoom into one spot where the phase shift happens we can see anything at this scale.\nFor the sake of argument lets make the prn modulation much faster.\nf_prn = 25e3/10 t=np.linspace(0, 12/f_prn,1400) signal = lambda t: carrier(t) * prn_np(t) plt.figure(figsize=(16,6)) plt.plot(t,signal(t),'b',lw=2) plt.title('CDMA BPSK',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.grid() plt.xlabel('Time(s)',size=16)  Now we see the phase shifts! To make what\u0026rsquo;s going on even clearer, lets overlay the PRN back on the chart to see how the phase shifts coincide with the edges of our PRN:\nf_prn = f_prn = 25e3/10 t=np.linspace(0,12/f_prn,1400) def prn_np(t): return [ prn_seq[int(ti*f_prn)%16] for ti in t] plt.figure(figsize=(16,6)) plt.plot(t,prn_np(t),color='red',lw=4) plt.plot(t,signal(t),'b',lw=2) plt.title('CDMA BPSK',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.grid() plt.xlabel('Time(s)',size=16)  f_prn = f_prn = 25e3/10 t=np.linspace(0,12/f_prn,1400) def prn_np(t): return [ prn_seq[int(ti*f_prn)%16] for ti in t] plt.figure(figsize=(16,6)) plt.plot(t,prn_np(t),color='red',lw=4) plt.plot(t,signal(t),'b',lw=2) plt.title('CDMA BPSK',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.grid() #plt.text(0.15e-8,1.2,'-1,-1') xt=t[-1]/16. for i in np.arange(16): plt.text((i+1/2.)*xt,1.2,prn_seq[i]) plt.xlabel('Time(s)',size=16)  Exercise  generate a sequence of codes with size 32 (PRN). generate the PRN BPSK graph. check the concideness between codes and graph.  prn_seq = [random.choice([1,-1]) for i in range(32)] print(prn_seq)  [1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1]  def prn_np(t): return [ prn_seq[int(ti*f_prn)%32] for ti in t]  f_prn = f_prn = 25e3/10 t=np.linspace(0,4/f_prn,400) plt.figure(figsize=(16,6)) plt.plot(t,prn_np(t),color='red',lw=4) plt.plot(t,signal(t),'b',lw=2) plt.title('CDMA BPSK',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.grid() plt.xlabel('Time[s]',size=16)  f_prn = f_prn = 25e3/10 t=np.linspace(0,4/f_prn,400) plt.figure(figsize=(16,6)) plt.plot(t,prn_np(t),color='red',lw=4) plt.plot(t,signal(t),'b',lw=2) plt.title('CDMA BPSK',size=20) plt.xlim([0,t[-1]]) plt.ylim([-1.5,1.5]) plt.grid() xt=t[-1]/32. for i in np.arange(32): plt.text((i+1/2.)*xt,1.2*prn_seq[i],prn_seq[i]) plt.xlabel('Time[s]',size=16)  ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"4b4890f4cf2c7e5ad29cd593e9e4d984","permalink":"https://patel999jay.github.io/post/cdma-using-python/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/cdma-using-python/","section":"post","summary":"CDMA signal using python","tags":"python","title":"CDMA signal using python","type":"post"},{"authors":["Jay Patel"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://patel999jay.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":["Jay Patel"],"categories":[],"content":"Underwater Acoustic Ray Tracing in the SOFAR(Sound Fixing and Ranging) Channel using Python import numpy as np import matplotlib.pyplot as plt %matplotlib inline import seaborn as sns sns.set() from tqdm import tqdm from IPython.display import HTML, display, Image from matplotlib import animation  # SPEED_OF_SOUND_SURFACE = 1480 # meters / second SOUND_SPEED_MIN = 1480 SOUND_SPEED_MAX = 1530 DEPTH_MIN = 0 # Ocean Surface DEPTH_MAX = 5500 # meters DEPTH_MIN_SPEED = 1100 # depth where minimum speed of sound is observed DEPTH_RANGE = np.arange(DEPTH_MIN, DEPTH_MAX + 1)  SOUND_GRADIENT_SHALLOW = (SOUND_SPEED_MIN - SOUND_SPEED_MAX) / (DEPTH_MIN_SPEED - DEPTH_MIN) SOUND_GRADIENT_DEEP = (SOUND_SPEED_MAX - SOUND_SPEED_MIN) / (DEPTH_MAX - DEPTH_MIN_SPEED) # vectorize the sound gradients # sound velocity gradient up to 1100 meters deep sound_grad_shallow_vec = np.full( (1, np.argwhere(DEPTH_RANGE == DEPTH_MIN_SPEED)[0][0]), SOUND_GRADIENT_SHALLOW ) # sound velocity gradient beyond 1100 meters sound_grad_deep_vec = np.full( (1, np.argmax(DEPTH_RANGE) - np.argwhere(DEPTH_RANGE == DEPTH_MIN_SPEED)[0][0]), SOUND_GRADIENT_DEEP ) # construct the sound velocity profile sound_velocity_profile = SOUND_SPEED_MIN + \\ (DEPTH_RANGE[:-1] - DEPTH_MIN_SPEED) * \\ np.append(sound_grad_shallow_vec, sound_grad_deep_vec) # plot the sound velocity profile fig = plt.figure(figsize=(8,6)) plt.plot(sound_velocity_profile, DEPTH_RANGE[:-1]) plt.plot([SOUND_SPEED_MIN],[DEPTH_MIN_SPEED], 'ro') plt.gca().invert_yaxis() plt.ylabel('Depth (m)') plt.xlabel('Sound Velocity (m/s)') plt.show()  SOURCE_DEPTH = DEPTH_MIN_SPEED SOURCE_SOUND_SPEED = SOUND_SPEED_MIN TRANSMISSION_ANGLE_RANGE = np.deg2rad(np.arange(-10, 11, 1)) # angle of transmission in rad angle_0_ind = np.argwhere(TRANSMISSION_ANGLE_RANGE == 0)[0][0] # index of the 0 degree mark  SIMULATION_STEPS = 20 # meters SIMULATION_RANGE = np.arange(0, 200e3 + SIMULATION_STEPS, SIMULATION_STEPS)  # Instantiate our matrices R = np.zeros((len(TRANSMISSION_ANGLE_RANGE), len(SIMULATION_RANGE))) z = np.zeros_like(R) c = np.zeros_like(R) theta = np.zeros_like(R) # Prime the initial conditions z[:, 0] = DEPTH_MIN_SPEED # we put the source at the depth of min sound speed R[:, 0] = -SOURCE_SOUND_SPEED / np.append( SOUND_GRADIENT_SHALLOW * np.cos(TRANSMISSION_ANGLE_RANGE[:angle_0_ind+1]), SOUND_GRADIENT_DEEP * np.cos(TRANSMISSION_ANGLE_RANGE[angle_0_ind+1:]), ) c[:, 0] = SOUND_SPEED_MIN theta[:, 0] = TRANSMISSION_ANGLE_RANGE  for j in tqdm(range(1, len(SIMULATION_RANGE))): for i in range(0, len(TRANSMISSION_ANGLE_RANGE)): if (z[i, j-1] == SOURCE_DEPTH) and (theta[i, j-1] == 0): c[i, j] = SOURCE_SOUND_SPEED theta[i, j] = 0 dz = 0 z[i, j] = SOURCE_DEPTH elif (z[i, j-1] \u0026lt; SOURCE_DEPTH) or (z[i, j-1] == SOURCE_DEPTH and theta[i, j-1] \u0026gt; 0): R[i, j] = -c[i, j-1] / (SOUND_GRADIENT_SHALLOW * np.cos(theta[i ,j-1])) theta[i, j] = np.arcsin( SIMULATION_STEPS / R[i, j-1] + np.sin(theta[i, j-1]) ) dz = R[i, j-1] * (np.cos(theta[i, j-1]) - np.cos(theta[i, j])) z[i, j] = z[i, j-1] + dz c[i, j] = SOURCE_SOUND_SPEED + SOUND_GRADIENT_SHALLOW * (z[i, j] - SOURCE_DEPTH) elif (z[i, j-1] \u0026gt; SOURCE_DEPTH) or (z[i, j-1] == SOURCE_DEPTH and theta[i, j-1] \u0026lt; 0): R[i, j] = -c[i, j-1] / (SOUND_GRADIENT_DEEP * np.cos(theta[i ,j-1])) theta[i, j] = np.arcsin( SIMULATION_STEPS / R[i, j-1] + np.sin(theta[i, j-1]) ) dz = R[i, j-1] * (np.cos(theta[i, j-1]) - np.cos(theta[i, j])) z[i, j] = z[i, j-1] + dz c[i, j] = SOURCE_SOUND_SPEED + SOUND_GRADIENT_DEEP * (z[i, j] - SOURCE_DEPTH)  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:03\u0026lt;00:00, 3283.26it/s]  plt.figure(figsize=(12,8)) for i in range(0, len(TRANSMISSION_ANGLE_RANGE)): plt.plot(SIMULATION_RANGE, z[i]) plt.gca().invert_yaxis() plt.title('Acoustic Ray Tracing') plt.xlabel('Range (m)') plt.ylabel('Depth (m)') plt.show()  duration_sec = 2 dpi = 100 bitrate = 100 fig, ax = plt.subplots(dpi=dpi) fig.text(0.89, 0.14, '@Jay Patel', fontsize=12, color='black', ha='right', va='bottom', alpha=0.75) fps = len(SIMULATION_RANGE) // duration_sec GifWriter = animation.ImageMagickFileWriter(fps, bitrate=bitrate ) save_filename = 'SOFAR_ray_trace.gif' with GifWriter.saving(fig, save_filename, dpi=dpi): for i in range(0, len(SIMULATION_RANGE) + 75, 75): plt.cla() ax.set_xlim(0, SIMULATION_RANGE[-1]) ax.set_ylim(500, 3500) ax.set_title(f\u0026quot;Acoustic Ray Tracing \\nSOFAR Channel\u0026quot;) plt.gca().invert_yaxis() plt.xlabel('Range (m)') plt.ylabel('Depth (m)') for a in range(0, len(TRANSMISSION_ANGLE_RANGE)): ax.plot(SIMULATION_RANGE[:i], z[a,:i]) GifWriter.grab_frame() plt.close()  SOURCE_DEPTH = DEPTH_MIN_SPEED SOURCE_SOUND_SPEED = SOUND_SPEED_MIN TRANSMISSION_ANGLE_RANGE = np.deg2rad(np.arange(-20, 20, 1)) # angle of transmission in rad -20 to 20 angle_0_ind = np.argwhere(TRANSMISSION_ANGLE_RANGE == 0)[0][0] # index of the 0 degree mark SIMULATION_STEPS = 20 # meters SIMULATION_RANGE = np.arange(0, 200e3 + SIMULATION_STEPS, SIMULATION_STEPS) # Instantiate our matrices R = np.zeros((len(TRANSMISSION_ANGLE_RANGE), len(SIMULATION_RANGE))) z = np.zeros_like(R) c = np.zeros_like(R) theta = np.zeros_like(R) # Prime the initial conditions z[:, 0] = DEPTH_MIN_SPEED # we put the source at the depth of min sound speed R[:, 0] = -SOURCE_SOUND_SPEED / np.append( SOUND_GRADIENT_SHALLOW * np.cos(TRANSMISSION_ANGLE_RANGE[:angle_0_ind+1]), SOUND_GRADIENT_DEEP * np.cos(TRANSMISSION_ANGLE_RANGE[angle_0_ind+1:]), ) c[:, 0] = SOUND_SPEED_MIN theta[:, 0] = TRANSMISSION_ANGLE_RANGE for j in tqdm(range(1, len(SIMULATION_RANGE))): for i in range(0, len(TRANSMISSION_ANGLE_RANGE)): if (z[i, j-1] == SOURCE_DEPTH) and (theta[i, j-1] == 0): c[i, j] = SOURCE_SOUND_SPEED theta[i, j] = 0 dz = 0 z[i, j] = SOURCE_DEPTH elif (z[i, j-1] \u0026lt; SOURCE_DEPTH) or (z[i, j-1] == SOURCE_DEPTH and theta[i, j-1] \u0026gt; 0): R[i, j] = -c[i, j-1] / (SOUND_GRADIENT_SHALLOW * np.cos(theta[i ,j-1])) theta[i, j] = np.arcsin( SIMULATION_STEPS / R[i, j-1] + np.sin(theta[i, j-1]) ) dz = R[i, j-1] * (np.cos(theta[i, j-1]) - np.cos(theta[i, j])) z[i, j] = z[i, j-1] + dz c[i, j] = SOURCE_SOUND_SPEED + SOUND_GRADIENT_SHALLOW * (z[i, j] - SOURCE_DEPTH) elif (z[i, j-1] \u0026gt; SOURCE_DEPTH) or (z[i, j-1] == SOURCE_DEPTH and theta[i, j-1] \u0026lt; 0): R[i, j] = -c[i, j-1] / (SOUND_GRADIENT_DEEP * np.cos(theta[i ,j-1])) theta[i, j] = np.arcsin( SIMULATION_STEPS / R[i, j-1] + np.sin(theta[i, j-1]) ) dz = R[i, j-1] * (np.cos(theta[i, j-1]) - np.cos(theta[i, j])) z[i, j] = z[i, j-1] + dz c[i, j] = SOURCE_SOUND_SPEED + SOUND_GRADIENT_DEEP * (z[i, j] - SOURCE_DEPTH) plt.figure(figsize=(16,12)) for i in range(0, len(TRANSMISSION_ANGLE_RANGE)): plt.plot(SIMULATION_RANGE, z[i]) plt.gca().invert_yaxis() plt.title('Acoustic Ray Tracing') plt.xlabel('Range (m)') plt.ylabel('Depth (m)') plt.show()  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06\u0026lt;00:00, 1616.31it/s]  duration_sec = 2 dpi = 100 bitrate = 100 fig, ax = plt.subplots(dpi=dpi) fig.text(0.89, 0.14, '@Jay Patel', fontsize=12, color='black', ha='right', va='bottom', alpha=0.75) fps = len(SIMULATION_RANGE) // duration_sec GifWriter = animation.ImageMagickFileWriter(fps, bitrate=bitrate ) save_filename = 'SOFAR_ray_trace_1.gif' with GifWriter.saving(fig, save_filename, dpi=dpi): for i in range(0, len(SIMULATION_RANGE) + 75, 75): plt.cla() ax.set_xlim(0, SIMULATION_RANGE[-1]) ax.set_ylim(500, 3500) ax.set_title(f\u0026quot;Acoustic Ray Tracing \\nSOFAR Channel\u0026quot;) plt.gca().invert_yaxis() plt.xlabel('Range (m)') plt.ylabel('Depth (m)') for a in range(0, len(TRANSMISSION_ANGLE_RANGE)): ax.plot(SIMULATION_RANGE[:i], z[a,:i]) GifWriter.grab_frame() plt.close()   References 1. https://brentonmallen.com/posts/underwater-acoustic-ray-tracing/ ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"b24b4849cfea625100576160eb0c252d","permalink":"https://patel999jay.github.io/post/underwateracousticsonar/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/underwateracousticsonar/","section":"post","summary":"Underwater Acoustic Ray Tracing in the SOFAR(Sound Fixing and Ranging) Channel using Python","tags":[],"title":"Underwater Acoustic Ray Tracing in the SOFAR(Sound Fixing and Ranging) Channel using Python","type":"post"},{"authors":["author","Niraj Tevar","Mehul Makwana","Dr J M Rathod"],"categories":[],"content":"Abstract A low profile, electrically small with omnidirectional vertically polarized radiation similar to a short monopole antenna is presented for UHF (400-520 MHz) band. It has compact and mechanically stable structure for mounting on to the roof of the Heavy duty vehicles such as Trains. It can also be employed with a ground plane (roof surface/rooftop) as in vehicle antenna is consider advantageous because the desired direction of communication are mostly independent of the orientation of the vehicle. The proposed antenna is made up of the compact size to reduce the overall antenna dimension. The simulation is carried out by using CST Microwave Studio Program. The effect of the antenna parameters on the impedance bandwidth will be investigated. It is easily embedded on the roof of the vehicle. Moreover, It has simple structure, low profile, easily mounted and relative good bandwidth (BW). It is also shown that this antenna is nearly omnidirectional over a majority fraction of bandwidth.\n","date":1471474551,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471474551,"objectID":"6c921fb7388733ec71f0484b595b57da","permalink":"https://patel999jay.github.io/publication/development-of-low-profile-antenna-for-point-to-train-communication/","publishdate":"2020-08-17T19:55:51-03:00","relpermalink":"/publication/development-of-low-profile-antenna-for-point-to-train-communication/","section":"publication","summary":"Point-To-Train Wifi antenna design and development","tags":[],"title":"Development of Low Profile Antenna for Point to Train Communication","type":"publication"},{"authors":null,"categories":null,"content":"ADM-Pluto-File-Transfer \u0026amp; FM Receiver PlutoSDR  Software-defined radio (SDR) is a radio communication system where components that have been traditionally implemented in hardware (e.g. mixers, filters, amplifiers, modulators/demodulators, detectors, etc.) are instead implemented by means of software on a personal computer or embedded system.[1] While the concept of SDR is not new, the rapidly evolving capabilities of digital electronics render practical many processes which were once only theoretically possible.\nSoftware Requirement :  1. GNU Radio software with IIO_Support (win_64) - (https://wiki.analog.com/resources/tools-software/linux-software/gnuradio_windows)  Hardware :  1. ADM-Pluto SDR Active Learning Module  Steps to perform :   Please make sure your pluto sdr connected properly and found from iio, To make sure please perform following command on terminal\niio_info -s    You should have something like this in your command prompt:\nIf you found your pluto successfully, Go ahead and open GNU Radio on your computer and open FileTxRx.grc and run the file.(Assuming you know how to run the file in GNU Radio, If not please look for Play arrow in the GNU Radio or press F5).  You may have to provide text file path again in GNU Radio in File Source and File Sink Block. You can use any text file for transmission. You can use the same text file from here - transmissionfile.txt (Please put this file on desktop and browse the same from File source block.)   Open transmissionfile.txt and review the contents in the file.\n  Make new text file on your desktop and name whatever you want but make sure you have same file extension. (you can also use file here name receivedfile.txt, This may have data in it, Please go aheah and delete all data from file and save that file again, Make it blank so you can see after transmission what data did you receive from Pluto).\n  While transmission, you can also see the Python based WX GUI For FFT TX and FFT Rx.\n  If you come across an error on GNU Radio saying that RuntimeError: Unable to set BB rate, Please make sure you provide correct sampling rate in PlutoSDR blocks in GNU Radio. If you don\u0026rsquo;t know how to find out correct sampling rate, Please perform following command on your command prompt and it will give you exact sampling rate.\n iio_attr -u \u0026lt;uri\u0026gt; -c cf-ad9361-lpc voltage0 sampling_frequency_available  You should have something like this in your command prompt:\nP.S. If you have more than one sampling rate, try each one and see what is the difference.\nFM Receiver with Pluto This version is tested for GNURadio 3.8  Just download the files from source folder and open fmradio_pluto_3.8.grc in GNU Radio application. You will see something like this:  Run the file or press F5. It will open the real time FM station (in my case i configure to receive 100.1 MHz station, Halifax, NS, Canada). You can see real time waterfall of FM Station and also can hear the sound too. If you have problem with audio change sampling rate accordingly.  Frequency Display Time Domain Display Waterfall Display Constellation Display This version is tested for GNURadio 3.7  Just download the files from source folder and open fmradio_pluto.grc in GNU Radio application. You will see something like this:  Run the file or press F5. It will open the real time FM station (in my case i configure to receive 100.1 MHz station, Halifax, NS, Canada). You can see real time waterfall of FM Station and also can hear the sound too. If you have problem with audio change sampling rate accordingly.  References 1. Wikipedia, https://en.wikipedia.org/wiki/Software-defined_radio ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://patel999jay.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"ADM-Pluto-File-Transfer \u0026 FM Receiver PlutoSDR","tags":["SDR"],"title":"ADALM PlutoSDR","type":"project"},{"authors":null,"categories":null,"content":"Bedford Bathy Plotting using Python  # Author : Jay Patel # 3D Bedford basin bathy import plotly.graph_objects as go import pandas as pd # Read data from a csv z_data = pd.read_csv('bathy_bedford.csv') fig = go.Figure(data=[go.Surface(z=z_data.values)]) fig.update_layout(title='Bedford Basin Elevation', autosize=True, width=900, height=900, margin=dict(l=65, r=50, b=65, t=90)) fig.show()  # cmap=plt.cm.viridis, linewidth=0.2  fig.update_traces(contours_z=dict(show=True, usecolormap=True, highlightcolor=\u0026quot;limegreen\u0026quot;, project_z=True))  Surface Plot With Contours import plotly.graph_objects as go import pandas as pd # Read data from a csv z_data = pd.read_csv('bathy_bedford.csv') fig = go.Figure(data=[go.Surface(z=z_data.values)]) fig.update_traces(contours_z=dict(show=True, usecolormap=True, highlightcolor=\u0026quot;limegreen\u0026quot;, project_z=True)) fig.update_layout(title='Bedford Basin Elevation', autosize=True, width=900, height=900, margin=dict(l=65, r=50, b=65, t=90)) fig.show()  import plotly.graph_objects as go import numpy as np import pandas as pd # Read data from a csv z_data = pd.read_csv('bathy_bedford.csv')  z = z_data.values sh_0, sh_1 = z.shape x, y = np.linspace(44.66875, 44.74791667, sh_0), np.linspace(-63.69791667, -63.52708333, sh_1)  import plotly.graph_objects as go import pandas as pd import numpy as np # Read data from a csv z_data = pd.read_csv('bathy_bedford.csv') z = z_data.values sh_0, sh_1 = z.shape x, y = np.linspace(44.66875, 44.74791667, sh_0), np.linspace(-63.69791667, -63.52708333, sh_1) fig = go.Figure(data=[go.Surface(z=z, x=x, y=y)]) fig.update_traces(contours_z=dict(show=True, usecolormap=True, highlightcolor=\u0026quot;limegreen\u0026quot;, project_z=True)) fig.update_layout(title='Bedford Basin Elevation', autosize=True, width=900, height=900, margin=dict(l=65, r=50, b=65, t=90)) fig.update_layout=dict(xaxis=dict(title='Latitude'), yaxis=dict(title='Longitude')) fig.show()  Configure Surface Contour Levels import plotly.graph_objects as go import pandas as pd import numpy as np # Read data from a csv z_data = pd.read_csv('bathy_bedford.csv') z = z_data.values sh_0, sh_1 = z.shape x, y = np.linspace(44.66875, 44.74791667, sh_0), np.linspace(-63.69791667, -63.52708333, sh_1) # fig = go.Figure(data=[go.Surface(z=z, x=x, y=y)]) fig = go.Figure(go.Surface( contours = { \u0026quot;x\u0026quot;: {\u0026quot;show\u0026quot;: True, \u0026quot;start\u0026quot;: 44.66875, \u0026quot;end\u0026quot;: 44.74791667, \u0026quot;size\u0026quot;: 0.04, \u0026quot;color\u0026quot;:\u0026quot;white\u0026quot;}, \u0026quot;z\u0026quot;: {\u0026quot;show\u0026quot;: True, \u0026quot;start\u0026quot;: -63.69791667, \u0026quot;end\u0026quot;: -63.52708333, \u0026quot;size\u0026quot;: 0.05} }, z=z, x=x, y=y)) fig.update_layout( scene = { \u0026quot;xaxis\u0026quot;: {\u0026quot;nticks\u0026quot;: 20}, \u0026quot;zaxis\u0026quot;: {\u0026quot;nticks\u0026quot;: 8}, 'camera_eye': {\u0026quot;x\u0026quot;: 0, \u0026quot;y\u0026quot;: -1, \u0026quot;z\u0026quot;: 0.5}, \u0026quot;aspectratio\u0026quot;: {\u0026quot;x\u0026quot;: 1, \u0026quot;y\u0026quot;: 1, \u0026quot;z\u0026quot;: 0.2} }) fig.show()  import plotly.graph_objects as go import pandas as pd import numpy as np # Read data from a csv z_data = pd.read_csv('bathy_bedford.csv') z = z_data.values sh_0, sh_1 = z.shape x, y = np.linspace(44.66875, 44.74791667, sh_0), np.linspace(-63.69791667, -63.52708333, sh_1) fig = go.Figure(data=[go.Surface(z=z, x=x, y=y)]) fig.update_traces(contours_z=dict(show=True, usecolormap=True, highlightcolor=\u0026quot;limegreen\u0026quot;, project_z=True)) fig.update_layout(title='\u0026lt;b\u0026gt;Bedford Basin Elevation\u0026lt;/b\u0026gt;',xaxis_title=\u0026quot;Latitude\u0026quot;, yaxis_title=\u0026quot;Longitude\u0026quot;,autosize=True, margin=dict(l=65, r=50, b=65, t=90)) fig.update_layout(scene = dict( xaxis_title='Latitude', yaxis_title='Longitude', zaxis_title='Elevation') ) # fig.update_layout(color='Elevation') fig.update_layout(coloraxis_colorbar=dict( title=\u0026quot;Elevation\u0026quot;, thicknessmode=\u0026quot;pixels\u0026quot;, thickness=50, lenmode=\u0026quot;pixels\u0026quot;, len=200, yanchor=\u0026quot;top\u0026quot;, y=1, ticks=\u0026quot;outside\u0026quot;, ticksuffix=\u0026quot;\u0026quot;, dtick=5 )) fig.show()  import plotly.graph_objects as go import pandas as pd import numpy as np # Read data from a csv z_data = pd.read_csv('bathy_bedford.csv') z = z_data.values sh_0, sh_1 = z.shape x, y = np.linspace(44.66875, 44.74791667, sh_0), np.linspace(-63.69791667, -63.52708333, sh_1) fig = go.Figure(data=[go.Surface(z=z, x=x, y=y,colorscale='Viridis')]) \u0026quot;\u0026quot;\u0026quot;The 'colorscale' property is a colorscale and may be specified as: - A list of colors that will be spaced evenly to create the colorscale. Many predefined colorscale lists are included in the sequential, diverging, and cyclical modules in the plotly.colors package. - A list of 2-element lists where the first element is the normalized color level value (starting at 0 and ending at 1), and the second item is a valid color string. (e.g. [[0, 'green'], [0.5, 'red'], [1.0, 'rgb(0, 0, 255)']]) - One of the following named colorscales: ['aggrnyl', 'agsunset', 'algae', 'amp', 'armyrose', 'balance', 'blackbody', 'bluered', 'blues', 'blugrn', 'bluyl', 'brbg', 'brwnyl', 'bugn', 'bupu', 'burg', 'burgyl', 'cividis', 'curl', 'darkmint', 'deep', 'delta', 'dense', 'earth', 'edge', 'electric', 'emrld', 'fall', 'geyser', 'gnbu', 'gray', 'greens', 'greys', 'haline', 'hot', 'hsv', 'ice', 'icefire', 'inferno', 'jet', 'magenta', 'magma', 'matter', 'mint', 'mrybm', 'mygbm', 'oranges', 'orrd', 'oryel', 'peach', 'phase', 'picnic', 'pinkyl', 'piyg', 'plasma', 'plotly3', 'portland', 'prgn', 'pubu', 'pubugn', 'puor', 'purd', 'purp', 'purples', 'purpor', 'rainbow', 'rdbu', 'rdgy', 'rdpu', 'rdylbu', 'rdylgn', 'redor', 'reds', 'solar', 'spectral', 'speed', 'sunset', 'sunsetdark', 'teal', 'tealgrn', 'tealrose', 'tempo', 'temps', 'thermal', 'tropic', 'turbid', 'twilight', 'viridis', 'ylgn', 'ylgnbu', 'ylorbr', 'ylorrd']. Appending '_r' to a named colorscale reverses it.\u0026quot;\u0026quot;\u0026quot; fig.update_traces(contours_z=dict(show=True, usecolormap=True, highlightcolor=\u0026quot;limegreen\u0026quot;, project_z=True)) fig.update_layout(title='Bedford Basin Elevation',xaxis_title=\u0026quot;Latitude\u0026quot;, yaxis_title=\u0026quot;Longitude\u0026quot;,autosize=False, width=900, height=900, margin=dict(l=65, r=50, b=65, t=90)) fig.update_layout(scene = dict( xaxis_title='Latitude', yaxis_title='Longitude', zaxis_title='Elevation'), margin=dict(r=20, b=10, l=10, t=10)) # fig.update_layout(color='Elevation') fig.update_layout(coloraxis_colorbar=dict( title=\u0026quot;Elevation\u0026quot;, thicknessmode=\u0026quot;pixels\u0026quot;, thickness=50, lenmode=\u0026quot;pixels\u0026quot;, len=200, yanchor=\u0026quot;top\u0026quot;, y=1, ticks=\u0026quot;outside\u0026quot;, ticksuffix=\u0026quot;\u0026quot;, dtick=5 )) fig.show()  Appendix Bathy Data z_data   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Unnamed: 0 44.66875 44.67291667 44.67708333 44.68125 44.68541667 44.68958333 44.69375 44.69791667 44.70208333 ... 44.71041667 44.71458333 44.71875 44.72291667 44.72708333 44.73125 44.73541667 44.73958333 44.74375 44.74791667   lon                          0 -63.697917 76.949219 77.085938 94.507813 109.914060 111.292970 88.378906 51.730469 47.687500 59.089844 ... 46.628906 39.363281 44.792969 52.582031 41.074219 32.304688 31.945313 37.171875 31.265625 35.207031   1 -63.693750 74.859375 75.480469 88.718750 104.511720 102.984380 72.757813 51.261719 57.562500 68.406250 ... 46.140625 35.457031 41.566406 46.582031 44.464844 43.144531 48.738281 41.949219 28.066406 41.425781   2 -63.689583 76.234375 75.566406 80.800781 85.156250 76.046875 55.621094 57.980469 73.234375 78.527344 ... 51.320313 30.578125 33.000000 44.218750 57.890625 63.746094 67.226563 60.589844 43.121094 37.597656   3 -63.685417 78.855469 77.718750 70.976563 61.859375 52.851563 54.816406 72.570313 84.394531 86.800781 ... 56.378906 30.882813 33.000000 52.328125 71.847656 84.273438 86.675781 79.574219 53.785156 28.941406   4 -63.681250 75.035156 67.761719 68.031250 65.218750 56.160156 68.144531 88.738281 93.468750 92.445313 ... 49.884766 24.603516 39.861328 64.859375 78.960938 86.257813 86.726563 84.812500 65.078125 40.824219   5 -63.677083 76.906250 68.015625 77.792969 76.507813 65.015625 77.984375 93.171875 95.757813 91.152344 ... 38.843773 14.459333 32.611832 63.052898 77.476563 83.761719 84.460938 82.933594 75.851563 53.343750   6 -63.672917 86.007813 81.906250 84.183594 79.460938 68.863281 74.460938 85.843750 89.839844 85.406250 ... 26.064667 -1.506614 12.861200 38.809372 63.070324 80.605469 85.308594 90.867188 82.867188 51.437500   7 -63.668750 95.003906 87.734375 72.562500 59.613281 62.312500 71.199219 72.628906 75.960938 75.221703 ... 9.954909 -11.974573 -4.805872 10.340685 43.335861 69.769524 76.273438 85.203125 71.476563 42.464844   8 -63.664583 97.148438 82.492188 64.988281 39.218735 43.938225 61.325375 49.881237 48.452190 52.963917 ... -1.673647 -8.128887 -10.653625 -4.688946 14.444967 40.492226 61.402344 61.308594 36.449219 18.914063   9 -63.660417 93.011719 83.011719 67.464821 28.027519 13.340724 22.575760 15.632376 6.809888 5.132569 ... -11.897992 -4.807637 3.286820 2.604772 5.671644 15.168005 27.855469 26.628906 10.945313 9.710938   10 -63.656250 92.898438 83.511719 55.145008 13.209535 -12.264346 -15.117385 -14.321301 -25.995922 -33.472305 ... -10.248625 8.080005 22.323267 20.934570 18.535183 15.214840 10.484375 12.101563 13.371094 24.375000   11 -63.652083 84.066406 64.296883 34.605164 2.242018 -22.517729 -30.148781 -34.749718 -41.952374 -41.779312 ... -3.999856 18.022432 42.588451 54.158203 35.542969 23.964844 23.730469 32.246094 38.230469 42.855469   12 -63.647917 65.445313 35.112190 6.273511 -16.426867 -32.295547 -41.835163 -51.907791 -56.872074 -45.036800 ... -2.225338 19.091228 53.738281 79.640625 58.265625 38.929688 38.921875 47.968750 60.488281 57.257813   13 -63.643750 43.226688 9.875418 -14.144128 -31.821207 -45.913952 -56.445293 -62.944271 -68.338936 -49.653156 ... -0.736164 20.028435 52.000000 77.394531 72.148438 60.503906 59.429688 56.027344 61.492188 60.273438   14 -63.639583 14.007681 -8.914713 -18.772408 -34.815582 -55.949837 -66.089462 -65.168015 -66.465927 -45.641136 ... 9.421118 38.420048 67.453125 75.691406 78.402344 80.929688 79.390625 64.707031 54.890625 51.156250   15 -63.635417 -7.310585 -18.513680 -22.575047 -35.414024 -54.700890 -63.991642 -62.630890 -56.582676 -35.162735 ... 26.824617 60.225838 77.328125 71.515625 79.382813 91.691406 88.488281 75.808594 57.250000 43.339844   16 -63.631250 -12.959548 -20.553957 -24.011562 -33.425610 -49.952095 -57.807667 -58.452568 -50.320042 -22.114317 ... 39.627213 56.666016 64.625000 60.617188 69.382813 84.894531 89.250000 83.457031 64.105469 44.339844   17 -63.627083 -13.959131 -20.879896 -24.619675 -30.599531 -42.064625 -46.732735 -45.736958 -38.605583 -8.134238 ... 38.142117 44.251953 49.472656 46.933594 51.566406 70.160156 81.511719 80.933594 70.406250 52.523438   18 -63.622917 0.690808 -9.467150 -21.900442 -26.936838 -27.090944 -28.230453 -25.843157 -19.252031 -2.559922 ... 29.576172 41.527344 44.617188 40.628906 38.910156 55.820313 72.777344 76.660156 72.941406 60.238281   19 -63.618750 33.239319 19.398363 -8.281146 -21.531794 -14.405942 -5.457515 -5.439976 -7.815783 -0.274054 ... 29.634766 42.472656 45.640625 40.773438 37.476563 48.804688 69.843750 79.410156 73.281250 65.578125   20 -63.614583 63.578960 33.142456 -8.284787 -10.527703 4.501016 15.951009 6.856074 -5.995221 2.971732 ... 31.964844 38.089844 43.308594 42.519531 44.750000 54.101563 69.886719 82.687500 73.929688 67.136719   21 -63.610417 70.817719 25.925608 -10.230622 9.744920 24.152803 21.304670 7.644289 -0.897256 6.740877 ... 33.261719 35.636719 38.226563 43.644531 51.324219 59.398438 65.488281 77.003906 81.035156 76.835938   22 -63.606250 55.557236 14.203660 -1.720311 16.641088 17.982437 11.728527 5.558494 5.703025 13.886730 ... 35.199219 36.750000 35.355469 40.335938 48.804688 53.933594 57.835938 67.910156 80.523438 86.218750   23 -63.602083 36.025299 2.190290 -1.339007 7.554595 6.734375 5.597656 4.179688 11.597656 26.957031 ... 44.718750 45.003906 39.687500 39.195313 46.054688 47.675781 51.292969 58.550781 69.648438 80.183594   24 -63.597917 8.810258 -4.524801 3.006743 5.879006 13.291016 18.996094 20.617188 26.906250 43.632813 ... 63.082031 58.554688 49.054688 45.753906 52.464844 47.886719 43.769531 49.820313 60.265625 69.031250   25 -63.593750 -10.357846 -2.310211 18.718382 29.412100 43.144531 47.375000 47.613281 46.789063 59.468750 ... 75.718750 64.488281 52.425781 54.796875 58.187500 51.171875 40.628906 39.328125 48.031250 54.558594   26 -63.589583 -4.446059 15.267798 35.644077 52.505859 66.007813 64.027344 60.007813 61.343750 70.480469 ... 73.003906 57.976563 57.664063 70.316406 61.886719 50.070313 41.804688 32.093750 34.121094 39.796875   27 -63.585417 10.070802 28.118652 42.909988 55.316406 68.027344 68.339844 63.441406 68.449219 72.671875 ... 68.878906 57.375000 72.867188 88.558594 67.378906 46.589844 40.140625 31.371094 26.300781 28.425781   28 -63.581250 23.047089 35.031254 47.410156 55.835938 64.968750 65.921875 65.269531 69.433594 68.640625 ... 70.011719 68.484375 81.964844 88.378906 71.328125 54.429688 46.496094 37.613281 29.402344 24.605469   29 -63.577083 29.660294 43.933594 54.765625 58.503906 59.875000 61.269531 65.808594 68.250000 67.292969 ... 70.148438 77.992188 85.140625 82.308594 73.621094 66.183594 63.078125 57.390625 40.878906 25.000000   30 -63.572917 31.014334 53.011719 65.511719 69.812500 67.406250 64.480469 65.234375 66.082031 67.046875 ... 70.800781 80.218750 82.531250 79.597656 74.093750 72.089844 72.535156 68.304688 53.062500 32.714844   31 -63.568750 26.085461 48.626953 68.445313 77.644531 72.324219 64.750000 60.253906 59.281250 59.570313 ... 74.175781 85.882813 81.031250 76.011719 74.222656 71.539063 68.039063 67.273438 59.007813 35.109375   32 -63.564583 15.733856 28.271484 46.269531 63.753906 64.000000 55.468750 47.593750 43.093750 44.507813 ... 73.300781 93.609375 85.214844 72.902344 68.187500 62.113281 55.867188 57.050781 48.832031 41.835938   33 -63.560417 16.391357 28.580078 28.265625 37.042969 50.828125 42.882813 29.406250 26.296875 34.031250 ... 65.316406 89.085938 79.992188 62.281250 57.343750 50.035156 42.109375 37.054688 40.128906 63.527344   34 -63.556250 35.735107 51.728516 35.523438 20.843750 34.964844 29.890625 18.320313 21.328125 33.257813 ... 47.628906 59.199219 56.316406 43.554688 39.011719 34.664063 31.308594 35.773438 59.132813 83.457031   35 -63.552083 53.774876 60.871094 40.660156 18.941406 21.210938 20.207031 18.796875 25.796875 40.980469 ... 30.445313 29.199219 31.417969 28.507813 24.871094 25.457031 33.128906 51.968750 77.597656 94.570313   36 -63.547917 59.230469 61.367188 51.703125 33.691406 26.390625 21.757813 19.949219 37.359375 56.464844 ... 38.128906 30.468750 30.625000 34.699219 36.746094 40.019531 50.718750 66.621094 84.746094 97.382813   37 -63.543750 64.832031 66.406250 59.792969 45.585938 34.242188 29.488281 38.558594 64.308594 76.347656 ... 61.476563 45.535156 39.082031 46.347656 49.382813 54.738281 62.695313 77.050781 95.820313 99.855469   38 -63.539583 73.113281 61.929688 49.589844 38.644531 39.300781 55.171875 74.441406 85.554688 88.195313 ... 72.500000 57.628906 44.191406 47.347656 54.886719 62.109375 73.921875 90.792969 101.320310 99.058594   39 -63.535417 63.765625 50.531250 45.089844 43.453125 57.082031 78.214844 90.632813 90.097656 85.585938 ... 71.574219 60.835938 50.472656 54.304688 69.460938 77.367188 83.960938 95.863281 101.292970 97.675781   40 -63.531250 47.578125 44.156250 48.628906 55.949219 64.972656 76.601563 88.078125 92.406250 87.617188 ... 68.554688 61.691406 59.355469 67.031250 82.750000 91.019531 90.761719 94.960938 96.988281 93.632813   41 -63.527083 41.800781 44.277344 50.859375 59.894531 68.699219 77.902344 88.875000 92.273438 87.335938 ... 70.550781 65.195313 65.718750 73.437500 86.222656 93.308594 92.941406 93.285156 90.976563 90.335938   42 -63.527083 41.800781 44.277344 50.859375 59.894531 68.699219 77.902344 88.875000 92.273438 87.335938 ... 70.550781 65.195313 65.718750 73.437500 86.222656 93.308594 92.941406 93.285156 90.976563 90.335938    43 rows Ã— 21 columns\n import pandas as pd import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D import plotly.graph_objects as go import pandas as pd import numpy as np df = pd.read_csv('POINT_DATA_TITLE.csv')  df.head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  x y z     0 -63.690000 44.738333 57   1 -63.689792 44.738333 57   2 -63.689583 44.738333 57   3 -63.689375 44.738333 56   4 -63.689167 44.738333 56     import numpy as np import matplotlib.pyplot as plt from matplotlib import cm # from matplotlib.ticker import LinearLocator, FormatStrFormatter from matplotlib import rc, rcParams from mpl_toolkits.mplot3d import Axes3D from scipy.interpolate import griddata import matplotlib.gridspec as gridspec # 2D-arrays from DataFrame x1 = np.linspace(df['x'].min(), df['x'].max(), len(df['x'].unique())) y1 = np.linspace(df['y'].min(), df['y'].max(), len(df['y'].unique())) \u0026quot;\u0026quot;\u0026quot; x, y via meshgrid for vectorized evaluation of 2 scalar/vector fields over 2-D grids, given one-dimensional coordinate arrays x1, x2,..., xn. \u0026quot;\u0026quot;\u0026quot; x2, y2 = np.meshgrid(x1, y1) # Interpolate unstructured D-dimensional data. z2 = griddata((df['x'], df['y']), df['z'], (x2, y2), method='cubic') # Ready to plot fig = plt.figure(211,figsize=(15,20)) ax = fig.add_subplot(211, projection='3d') spec = gridspec.GridSpec(ncols=1, nrows=2, height_ratios=[4, 1]) surf = ax.plot_surface(x2, y2, z2, rstride=1, cstride=1, cmap=cm.terrain, linewidth=1, antialiased=False) ax.view_init(45,-55) cset = ax.contourf(x2, y2, z2, zdir='z2', offset=-80, cmap=cm.terrain, antialiased=True) rcParams['legend.fontsize'] = 20 rc('text', usetex=True) rc('axes', linewidth=2) rc('font', weight='bold') rcParams['text.latex.preamble'] = [r'\\usepackage{sfmath} \\boldmath'] ax.xaxis.set_tick_params(labelsize=20) ax.yaxis.set_tick_params(labelsize=20) ax.zaxis.set_tick_params(labelsize=20) ax.set_zticks([-70, -50, -30, -10, 10, 30, 50, 70, 90, 110]) plt.title(r'\\textbf{Bedford Basin Bathymatry}', fontsize=20) plt.xlabel(r'\\textbf{Latitude}', fontsize=20, labelpad= 23) plt.ylabel(r'\\textbf{Longitude}', fontsize=20, labelpad= 20) ax.set_zlabel(r'\\textbf{Elevation}', fontsize=20, labelpad= 10) fig.savefig('Bedford_BASIN_BATHY_view5.png', dpi=600) import matplotlib.pyplot as plt import matplotlib as mpl fig, ax = plt.subplots(figsize=(15, 1)) # ax = fig.add_subplot(111) fig.subplots_adjust(bottom=0.5) cmap = mpl.cm.terrain norm = mpl.colors.Normalize(vmin=-80, vmax=100) cb1 = mpl.colorbar.ColorbarBase(ax, cmap=cmap, norm=norm, orientation='horizontal') cb1.set_label('Elevation', fontsize=20, weight='bold') plt.setp(ax.get_xticklabels(), fontsize=20) fig.savefig('Bedford_BASIN_BATHY_view8.png', dpi=600) plt.show()  import matplotlib.pyplot as plt import matplotlib as mpl left, width = 0.07, 0.65 bottom, height = 0.1, .8 bottom_h = left_h = left+width+0.02 rect_cones = [left, bottom, width, height] rect_box = [left_h, bottom, 0.05, height] fig = plt.figure(figsize=(14,7), dpi=300) cones = plt.axes(rect_cones,projection='3d') box = plt.axes(rect_box) cones.plot_surface(x2, y2, z2, rstride=1, cstride=1, cmap=cm.terrain, linewidth=1, antialiased=False) cones.set_zlim([-80, 110]) cones.view_init(45,-55) cset = cones.contourf(x2, y2, z2, zdir='z2', offset=-80, cmap=cm.terrain, antialiased=True) rcParams['legend.fontsize'] = 20 rc('text', usetex=True) rc('axes', linewidth=2) rc('font', weight='bold') rcParams['text.latex.preamble'] = [r'\\usepackage{sfmath} \\boldmath'] cones.xaxis.set_tick_params(labelsize=20) cones.yaxis.set_tick_params(labelsize=20) cones.zaxis.set_tick_params(labelsize=20) cones.set_xlabel('Latitude', fontsize=20, labelpad= 23, weight='bold') cones.set_ylabel('Longitude', fontsize=20, labelpad= 20, weight='bold') cones.set_zlabel('Elevation', fontsize=20, labelpad= 10, weight='bold') fig.suptitle('Bedford Basin Bathymatry', fontsize=20, weight='bold') cmap = mpl.cm.terrain norm = mpl.colors.Normalize(vmin=-80, vmax=110) cb1 = mpl.colorbar.ColorbarBase(box, cmap=cmap, norm=norm, orientation='vertical', extend='both') plt.setp(box.get_yticklabels(), fontsize=16); fig.savefig('Bedford_BASIN_BATHY_Final_fig.png', dpi=600)  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"52d0c3dde2e5c0baae7edb32b900956a","permalink":"https://patel999jay.github.io/project/bedford-bathy/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/bedford-bathy/","section":"project","summary":"Bedford Bathy Plotting using python","tags":["python"],"title":"Bedford Bathy Plotting using python","type":"project"},{"authors":["Jay Patel","Niraj Tevar","Mehul Makwana","Dr J M Rathod"],"categories":[],"content":"Abstract A proposed work present UHF (400-520 MHz) low-profile (compact size) antenna for mounting on to the roof of the space constrained auto motives such as Trains, with omnidirectional vertically polarized radiation. The proposed design has less than Î»/32 dimension in height. It can also be mounted with a ground plane (roof surface/rooftop). The geometry of the proposed antenna is taken from a short monopole antenna fed at appropriate location for proper impedance matching. The distance between the shorting end and antenna radiator is given by Î»/8 and proper feeding position can enable it to match to 50 Î© coaxial line. The antenna is designed and simulated by CST Microwave Studio Program. The effect of the antenna parameters on the bandwidth will be investigated. Moreover, the proposed antenna, easily mounted on vehicle roof, has small dimensions, low profile, easy mounting and relatively good bandwidth (BW). It is also shown that this antenna is nearly omnidirectional in azimuth plane over a majority fraction of bandwidth.\n","date":1458772555,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458772555,"objectID":"fbc64cdf683292c6023f570c816efb97","permalink":"https://patel999jay.github.io/publication/design-and-simulation-of-roof-mounted-low-profile-uhf-antenna-for-auto-motives/","publishdate":"2020-08-17T19:35:55-03:00","relpermalink":"/publication/design-and-simulation-of-roof-mounted-low-profile-uhf-antenna-for-auto-motives/","section":"publication","summary":"A UHF Antenna design, development and testing","tags":["UHF antennas","low profile antennas","Omnidirectional antenna","Roof mounted antennas","monopole antennas"],"title":"Design and Simulation of Roof Mounted Low Profile UHF Antenna for Auto Motives","type":"publication"},{"authors":["Jay Patel","Niraj Tevar","Dr J M Rathod","Tanvi Shah"],"categories":null,"content":"Abstract Proposed work presents a UHF (400-520 MHz) antenna with compact structure for mounting on to the roof of Auto motives such as Train and Hammers. It can also be employed with a ground plane (roof surface/rooftop) as it is considered advantageous because the desired direction of communication are mostly independent of the orientation of the vehicle. The proposed antenna is made up of the compact size to reduce the overall antenna dimension. The simulation is carried out by using CST Microwave Studio Program and the effect of the antenna parameters on the bandwidth will be investigated. It is easily embedded on the roof of the vehicle. Moreover, the proposed antenna has simple structure, low profile, easy fabrication and relative good bandwidth (BW). It is also shown that this antenna is nearly omnidirectional over a majority fraction of bandwidth.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://patel999jay.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Design and simulation of UHF Roof mounted antenna for metro trains","tags":["UHF antennas","Roof mounted antenna","Heavy duty vehicular antenna"],"title":"Design and Simulation of UHF antenna for Roof mounted vehicular and heavy duty applications","type":"publication"}]